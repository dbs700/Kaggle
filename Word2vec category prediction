library(h2o)
h2o.init()

# Import the craigslist dataset into H2O:
job_title <- h2o.importFile("https://s3.amazonaws.com/h2o-public-test-data/smalldata/craigslistJobTitles.csv",
                            col.names = c("category", "jobtitle"),
                            col.types = c("Enum", "String"),
                            header = TRUE)
STOP_WORDS = c("ax", "i", "you", "edu", "s", "t", "m", "subject", "can",
               "lines", "re", "what", "there", "all", "we", "one", "the",
               "a", "an", "of", "or", "in", "for", "by", "on", "but", "is",
               "in", "a", "not", "with", "as", "was", "if", "they", "are",
               "this", "and", "it", "have", "from", "at", "my", "be", "by",
               "not", "that", "to", "from", "com", "org", "like", "likes",
               "so")

# Make the 'tokenize' function:
tokenize <- function(sentences, stop.words = STOP_WORDS) {
  tokenized <- h2o.tokenize(sentences, "\\\\W+")
  tokenized.lower <- h2o.tolower(tokenized)
  tokenized.lengths <- h2o.nchar(tokenized.lower)
  tokenized.filtered <- tokenized.lower[is.na(tokenized.lengths) || tokenized.lengths >= 2,]
  tokenized.words <- tokenized.filtered[h2o.grep("[0-9]", tokenized.filtered, invert = TRUE, output.logical = TRUE),]
  tokenized.words[is.na(tokenized.words) || (! tokenized.words %in% STOP_WORDS),]
}

# Make the 'predict' function:
.predict <- function(job_title, w2v, gbm) {
  words <- tokenize(as.character(as.h2o(job_title)))
  job_title_vec <- h2o.transform(w2v, words, aggregate_method = "AVERAGE")
  h2o.predict(gbm, job_title_vec)
}

# Break job titles into sequence of words:
words <- tokenize(job_title$jobtitle)

# Build the word2vec model:
w2v_model <- h2o.word2vec(words, sent_sample_rate = 0, epochs = 10)

# Find synonyms for the word "teacher":
print(h2o.findSynonyms(w2v_model, "teacher", count = 5))

# Calculate a vector for each job title:
job_title_vecs <- h2o.transform(w2v_model, words, aggregate_method = "AVERAGE")

# Prepare training & validation data (keep only job titles made of known words):
valid_job_titles <- ! is.na(job_title_vecs$C1)
data <- h2o.cbind(job_title[valid_job_titles, "category"], job_title_vecs[valid_job_titles, ])
data_split <- h2o.splitFrame(data, ratios = 0.8)

# Build a basic GBM model:
gbm_model <- h2o.gbm(x = names(job_title_vecs),
                     y = "category",
                     training_frame = data_split[[1]],
                     validation_frame = data_split[[2]])

# Predict:
print(.predict("school teacher having holidays every month", w2v_model, gbm_model))
print(.predict("developer with 3+ Java experience, jumping", w2v_model, gbm_model))
print(.predict("Financial accountant CPA preferred", w2v_model, gbm_model))
